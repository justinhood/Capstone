\documentclass[letterpaper,10pt]{article}
\usepackage[top=2cm, bottom=1.5cm, left=1cm, right=1cm]{geometry}
\usepackage{amsmath, amssymb, amsthm,graphicx, enumitem}
\usepackage{fancyhdr}
\pagestyle{fancy}

\lhead{\today}
\chead{MSCS 791 Intro Reading \#1}
\rhead{Justin Hood}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newtheorem{lem}{Lemma}

\begin{document}
\begin{itemize}
\item After an initial skim of the network efficiency paper its purpose appears to be two-fold. The paper primarily focuses on delivering the results of numerical simulation of the effects of perturbing the packaging network from equilibrium, and delivering those results in a non-mathematical context that could be presented to industry clients. The paper also lays a framework for expanding the model they constructed into a general form for more complex systems or networks.
\item In ``Analyzing Packaging Network Efficiency", the authors were commissioned by the Kimberly-Clark Corporation to model the effects of machine failure on their packaging network, and other networks in general. In particular, the authors were concerned with the packaging network for Huggies\texttrademark .  This network in particular consists of four ``stages",
\begin{enumerate}
\item Network Input (Diapers)
\item Packaging Diapers into Sleeves
\item Packaging Sleeves into Boxes
\item Network Output (Boxes of Diapers on Pallets)
\end{enumerate}
and between each stage are a number of ``buffers" that transport the diapers between the machines in a given stage. For the Huggies\texttrademark packaging network, the number of machines in a given stage varies depending on the speed of the machines. Given that the packaging network can be drawn in a way that is analogous to current running through an electrical circuit, a parallel of Kirchhoff's first law takes shape. That is to say, that the rate of product flowing into a stage of the packaging process is less than or equal to the net processing rate of all machines in the stage. This becomes apparent when considering the network as a whole, as too much product flowing into a given stage would back up the entire process, most likely resulting in scrapped product.\\\\
The authors began by drawing the entire packaging system as a connected graph, with nodes corresponding to machines in the network, and edges corresponding to buffer connections between the machines of adjacent stages. When connected in this manner, the authors were able to apply their analogue of Kirchhoff's law to linearly constrain the system, creating a system of rules to optimize. Using LINDO the authors were able to optimize the values of the network based on the constraints provided by Kimberly-Clark. These optimized rate values form the steady state solution to the network, and as such the authors were then able to implement machine failure into the system to study the effects on network throughput.\\\\
Once the equilibrium values of the network had been computed, the authors considered machine failure. According two Kimberly-Clark, there are two primary types of machine failure that needed to be considered, short-term and long-term. The authors also note that machines most often fail within 20 seconds of being started, and that approximately 50\% of all machines will fail within two hours of uptime. Using this data, the authors chose to model the probability of machine failure with a log-normal PDF, using the provided parameters from the data. This accounts for the spike in failure probability at the beginning of the process, with a gradual reduction as time goes on for the next two hours of run time. With this model of failure probability in place, the authors then consider the downtime distribution for machine repair. Given that there are two lengths of common repairs, 30s and 30min, the authors combined two different PDF's into a single density function, weighted based on repair data from Kimberly-Clark. With this PDF in hand, the CDF can be computed in order to define the ``hazard" rate for the machine repair times.\\\\
Finally, the authors consider implementing these machine failure functions in a simplified model of the network, in order to test for the effects of altering input variables. Their simplified model uses a three stage system, feeding diapers in, bagging them, and finally boxing them. In this new system, the failure rates of the machines are modeled along with a count of wasted product due to machine failure, which also takes into account damage to product that is still in the buffer when the machine goes down. These values also come from the Kimberly-Clark data. Along with waste, the simulation also considers the effect of throughput in the system when one or more machine is down; i.e. the effectiveness of the network as a whole. Because the goal is to improve the effectiveness of the packaging network, throughput and waste are the primary metrics that can be measured to describe the results. After running 500 trials for each set of input perturbations, statistics for the resultant sets were computed. The authors discovered that when the mean time for machines to fail was increased, ``Better Machines", the amount of waste in the network was reduced, and the daily throughput was increased as well, though only marginally. When the mean repair time was reduced, ``Improved repair protocols", the authors discovered that throughput was increased. The conclusion being that improving throughput is closely tied to repair time, and waste is tied to machine reliability.
\item Figure Analysis:
\begin{enumerate}
\item This figure does clearly explain the ``Law of Conservation of Diapers", though it is hard to take out of the context of the paragraph that it is related to. Additionally, the color scheme could be challenging for someone who is color blind to interpret. I feel that the addition of vertical lines to partition each ``stage" of the process could have improved the readability.
\item This figure is helpful for understanding the optimized throughput of the model. The numbers are easy to read and add in your head, so it is easy to see how the flow would occur.
\item This figure describes the sharp uptick in failure at the startup of the machine. It could possibly be improved by cutting the length of the $x$ axis to show the degrading slope more clearly towards the beginning, as most readers of this type of paper are likely familiar with exponential decay.
\item I found this figure to be quite helpful in understanding what the weighted repair time PDF looks like. It also clearly encompasses the two types of repair described in the paper itself.
\item This figure felt slightly unnecessary, as both the first and second figures describe such a system in more detail, it would likely have been sufficient to merely write a description that detailed the removal of the final step.
\item This figure clearly shows the distribution for the standard conditions, and was helpful for understand the scope of a given simulation run.
\item This figure was helpful for showing the results from modifying the long term repair time.
\item This figure was helpful for showing the results from modifying the median failure time.\\\\
Overall, I felt that the figures did a good job of explaining the data, though I would have made a few minor quality of life changes.
\end{enumerate}
\item While reading this paper, I enjoyed the level of detail that was put into explaining the linear programming approach to the problem. By clearly mapping out the relationships in a sort of ``matrix form", it was easy to understand what the LINDO software was attempting to accomplish. I also felt that the box plots at the end of the paper clearly enumerated the results in a very readable way.
\item If I was to make any changes, I would probably change the scopes of the machine failure section and the results section. While it is interesting to read about how the PDF's were chosen, and to see the equations, for the scope of this paper it seems slightly overboard, as a representative for Kimberly-Clark may not have the mathematics background to benefit from it. For the scope of the problem, as well as the potential audience, it would most likely be more useful to provide a more detailed results section that showcased all of the changes that were tested, as well as the concise results that were given in the paper. In addition, I would also have considered providing more summary statistics of the data given, to increase the understanding of the problem space itself.
\item The questions I have after reading the paper,
\begin{enumerate}
\item Why was the final model that was run so simplified compared to the model from Figure 1.?
\begin{enumerate}
\item Was it due to computational time constraints?
\end{enumerate}
\item How might this model have been used on a more complex network, especially without having to rely on LINDO to recompute the steady states each time?
\end{enumerate}
\end{itemize}
\end{document}
